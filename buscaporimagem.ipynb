{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN1AdhMJ/9cSYO67xcVUWxx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aBaldoqui/ImageSearch/blob/main/buscaporimagem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_Jj0WlaLIhu",
        "outputId": "720c91ea-a817-4e59-ccec-0b6dd5f90408"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:03<00:00, 33.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Carregar o modelo pré-treinado\n",
        "model = models.resnet50(pretrained=True)\n",
        "model = torch.nn.Sequential(*list(model.children())[:-1])  # Remover a última camada de classificação\n",
        "model.eval()\n",
        "\n",
        "# Transformação da imagem\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "def extract_embedding(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image = preprocess(image).unsqueeze(0)  # Adiciona batch dimension\n",
        "    with torch.no_grad():\n",
        "        embedding = model(image).squeeze()  # Remove batch dimension\n",
        "    return embedding.numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(embedding1, embedding2):\n",
        "    dot_product = np.dot(embedding1, embedding2)\n",
        "    norm1 = np.linalg.norm(embedding1)\n",
        "    norm2 = np.linalg.norm(embedding2)\n",
        "    return dot_product / (norm1 * norm2)\n"
      ],
      "metadata": {
        "id": "bC67BdCXLV9b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv-9gbGOL3Z6",
        "outputId": "4690c32d-2a05-4c7e-ad29-8300d480acd4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Definir o caminho da pasta 'roupas'\n",
        "image_dir = '/content/roupas'\n",
        "\n",
        "# Listar todos os arquivos .jpg na pasta 'roupas'\n",
        "image_paths = [os.path.join(image_dir, fname) for fname in os.listdir(image_dir) if fname.endswith('.jpg')]\n",
        "\n",
        "# Extrair os embeddings e armazená-los na lista 'embeddings'\n",
        "embeddings = []\n",
        "for image_path in image_paths:\n",
        "    emb = extract_embedding(image_path)\n",
        "    embeddings.append(emb)\n",
        "\n",
        "# Converter a lista de embeddings para um array NumPy\n",
        "embeddings = np.array(embeddings)\n",
        "\n",
        "# Mostrar a forma do array de embeddings (ex: número de imagens, dimensão do embedding)\n",
        "print(embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWIgpgylMPy3",
        "outputId": "9c946e16-86b2-4193-ff48-97f6357bbe7b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjzneoszPIq4",
        "outputId": "c1ede7d0-ffc4-4212-8896-c0551f194a89"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que temos embeddings de todas as imagens em 'embeddings'\n",
        "d = embeddings.shape[1]  # Dimensão do embedding\n",
        "index = faiss.IndexFlatL2(d)  # Indexador de similaridade com L2 (euclidiana)\n",
        "index.add(embeddings)  # Adicionar os embeddings ao indexador\n",
        "\n",
        "# Buscar imagem mais similar\n",
        "D, I = index.search(np.array([embeddings[11]]), k=5)  # Retorna os 5 mais similares\n",
        "\n",
        "print(I)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shfyVbmlMGUI",
        "outputId": "91edbea9-5a20-4940-9ced-7c5ecd847602"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11 10  3  4 16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kJ6avLfVP0pm",
        "outputId": "4002d173-baed-4c9b-e083-d111bac2374f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/roupas/3094ba16a14e554292846f4551169788.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}